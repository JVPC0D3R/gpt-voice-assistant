{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1223,"status":"ok","timestamp":1682264035599,"user":{"displayName":"JAIME VILLA PLAZA","userId":"16556643678799076434"},"user_tz":-120},"id":"GqjpNTL0lXw3"},"outputs":[{"name":"stdout","output_type":"stream","text":["402\n"]}],"source":["from dataset import GOOGLE, GOODBYE, CHAT, VISION\n","data = GOOGLE + GOODBYE + CHAT + VISION\n","\n","print(len(data))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"elapsed":126030,"status":"ok","timestamp":1682264960652,"user":{"displayName":"JAIME VILLA PLAZA","userId":"16556643678799076434"},"user_tz":-120},"id":"VblJOqkFoJHe","outputId":"b3c1f423-6624-4b14-dadf-68c7adec20cb"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from sklearn.model_selection import train_test_split\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Load the tokenizer and the model\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n","\n","# Prepare the dataset\n","texts = [item[0] for item in data]\n","labels = [item[1] for item in data]\n","label_map = {'vision': 0, 'chat': 1, 'goodbye': 2, 'google': 3}\n","labels = [label_map[label] for label in labels]\n","\n","# Split the dataset into training and validation sets\n","train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n","\n","# Tokenize the text\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n","\n","# Create the custom dataset\n","train_dataset = CustomDataset(train_encodings, train_labels)\n","val_dataset = CustomDataset(val_encodings, val_labels)\n","\n","# Create the Trainer\n","training_args = TrainingArguments(\n","    output_dir='../models',\n","    num_train_epochs=10,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    logging_dir='./logs',\n","    learning_rate=5e-5,\n","    save_total_limit=1,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",  # Save a checkpoint at the end of each epoch\n",")\n","\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")\n","\n","# Fine-tune the model\n","trainer.train()\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5146,"status":"ok","timestamp":1682264988626,"user":{"displayName":"JAIME VILLA PLAZA","userId":"16556643678799076434"},"user_tz":-120},"id":"zsmKH6j0qvzJ","outputId":"ae99c575-a283-4b1f-8419-0a2c547203f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello there! : chat\n","I'd like you to tell me about powerlifting : chat\n","Can you see me? : vision\n","What do you see in this image? : vision\n","See you tomorrow! : goodbye\n","Goodbye GPT : goodbye\n","What is a compiled programing language? : google\n","How many calories does Ultra White Monster Energy have? : google\n"]}],"source":["from transformers import pipeline\n","\n","# Load the fine-tuned model\n","model_path = '../models/cd_CKPT_IV'\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","classifier = pipeline('text-classification', model=model_path, tokenizer=tokenizer)\n","\n","def command_filter(prompt):\n","    # Classify the input prompt\n","    result = classifier(prompt)\n","    command_id = int(result[0]['label'].split('_')[-1])\n","    command = {0: 'vision', 1: 'chat', 2: 'goodbye', 3: 'google'}[command_id]\n","\n","    return command\n","    \n","# Example prompts\n","\n","prompts = [\"Hello there!\",\n","           \"I'd like you to tell me about powerlifting\",\n","           \"Can you see me?\",\n","           \"What do you see in this image?\",\n","           \"See you tomorrow!\",\n","           \"Goodbye GPT\",\n","           \"What is a compiled programing language?\",\n","           \"How many calories does Ultra White Monster Energy have?\"]\n","\n","for prompt in prompts:\n","\n","\n","    print(f'{prompt} : {command_filter(prompt)}')\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMA1LT8Sj9ffscvm4bHdwRG","mount_file_id":"1tIekOnaB887ksJ8Tvr5AF9EbQSmgwHs2","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}
